{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.7.1+cu110 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install torchtext==0.8.1\n",
    "!pip install git+https://github.com/SKT-AI/KoBART#egg=kobart\n",
    "!pip install transformers==4.11.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd drive/MyDrive/자연어쩔티비내리는호남선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --recurse-submodules https://github.com/haven-jeon/KoBART-chatbot.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd KoBART-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kobart import get_kobart_tokenizer\n",
    "get_kobart_tokenizer(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python kobart_chit_chat.py  --gradient_clip_val 1.0 --max_epochs 5 --default_root_dir logs --model_path hyunwoongko/kobart --tokenizer_path emji_tokenizer --chat --gpus 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from transformers import BartForConditionalGeneration, BartConfig, PreTrainedTokenizerFast\n",
    "import torch\n",
    "\n",
    "class BartModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = BartForConditionalGeneration.from_pretrained('hyunwoongko/kobart')  \n",
    "      \n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "def ckpt_to_pretrained(ckpt_path, pretrained_path):\n",
    "    model = BartModel()\n",
    "    ckpt = torch.load(ckpt_path)\n",
    "    model.load_state_dict(ckpt['state_dict'])\n",
    "    model.model.save_pretrained(pretrained_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_to_pretrained('logs/kobart_chitchat-last.ckpt', 'ver_2')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
